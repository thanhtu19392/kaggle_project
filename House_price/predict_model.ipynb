{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 59.6 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sns.set(style = \"whitegrid\", color_codes = True)\n",
    "sns.set(font_scale = 1)\n",
    "#from astropy.table import Table, Column\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn import clone\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score, roc_curve, mean_squared_error\n",
    "import pickle\n",
    "import random\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.56 ms\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns which have percentage of missing values superior threshold\n",
    "class DropColumnsWithMissingData(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    drop all columns which have percentage of missing values superior threshold\n",
    "    \"\"\"\n",
    "    def __init__(self, thresholds=0.40):\n",
    "        self.thresholds = thresholds\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        a = X.isnull().mean()\n",
    "        self.kept_columns = a.index[a < self.thresholds].tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.kept_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "class select_features(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Select categorical features or numerical features \n",
    "    \"\"\"\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "         \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.features]\n",
    "\n",
    "    \n",
    "class FillMissingValues(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Fill missing values \n",
    "    'nan' for categorical features\n",
    "    or -999 for numerical features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, replace_value):\n",
    "        self.replace_value = replace_value\n",
    "        # replace_value = 'nan' for filling missing data in categorical features\n",
    "        # or -999 in numerical features\n",
    "       \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.replace_value)\n",
    "    \n",
    "    \n",
    "class ColumnApplier(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Some sklearn transformers can apply only on ONE column at a time (such as LabelEnconder())\n",
    "    Wrap them with ColumnApplier to apply on all columns in the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, underlying):\n",
    "        self.underlying = underlying\n",
    "        #TODO: underlying is one model method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        m = {}\n",
    "        X = pd.DataFrame(X)  # TODO: :( reimplement in pure numpy?\n",
    "        for c in X.columns:\n",
    "            k = clone(self.underlying) \n",
    "            #TODO: clone helps to construct a new estimator with the same parameters.\n",
    "            #      deep copy of the model in an estimator without actually copying attached data\n",
    "            \n",
    "            k.fit(X[c])\n",
    "            # fit model k for every column in X \n",
    "            \n",
    "            m[c] = k\n",
    "            # put it in dictionary with column c as key and k as items\n",
    "        \n",
    "        self._column_stages = m\n",
    "        # self.column_stages is a dictionary with column c in X as key and model k.fit as items \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        ret = {}\n",
    "        X = pd.DataFrame(X)\n",
    "        for c, k in self._column_stages.items():\n",
    "            ret[c] = k.transform(X[c])\n",
    "            # ret is a dict which has c as key and k.transform as items\n",
    "        return pd.DataFrame(ret)[X.columns]  # keep the same order\n",
    "\n",
    "class TolerantLabelEncoder(LabelEncoder):\n",
    "    \"\"\"\n",
    "    LabelEncoder is not tolerant to unseen values\n",
    "    \"\"\"\n",
    "    def transform(self, y):\n",
    "        return np.searchsorted(self.classes_, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 36.3 ms\n"
     ]
    }
   ],
   "source": [
    "#Import training data\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "#Import test data\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.69 ms\n"
     ]
    }
   ],
   "source": [
    "train.drop(['Id'], axis= 1, inplace= True)\n",
    "test.drop(['Id'], axis= 1 , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.26 ms\n"
     ]
    }
   ],
   "source": [
    "Xtrain = train.ix[:, train.columns != 'SalePrice']\n",
    "ytrain = train.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.9 ms\n"
     ]
    }
   ],
   "source": [
    "X_train = DropColumnsWithMissingData(thresholds=0.90).fit_transform(Xtrain)\n",
    "\n",
    "CAT = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "NUM = X_train.select_dtypes(exclude=[\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.39 ms\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "preproc_le = make_pipeline (\n",
    "    DropColumnsWithMissingData(thresholds=0.90),\n",
    "    make_union(make_pipeline(\n",
    "        select_features(CAT),\n",
    "        FillMissingValues('nan'),\n",
    "        ColumnApplier(TolerantLabelEncoder())\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        select_features(NUM),\n",
    "        FillMissingValues(-999),\n",
    "        StandardScaler()\n",
    "    )\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.25 ms\n"
     ]
    }
   ],
   "source": [
    "### One-hot Encoding\n",
    "preproc_ohe = make_pipeline (\n",
    "    DropColumnsWithMissingData(thresholds=0.9),\n",
    "    make_union(\n",
    "    make_pipeline(\n",
    "        select_features(CAT),\n",
    "        FillMissingValues('nan'),\n",
    "        ColumnApplier(TolerantLabelEncoder()),\n",
    "        OneHotEncoder(handle_unknown = 'ignore')\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        select_features(NUM),\n",
    "        FillMissingValues(-999),\n",
    "        StandardScaler()        \n",
    "    )\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data set into 2 part: train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.87 ms\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(Xtrain, ytrain, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 79)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.32 ms\n"
     ]
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with random search or GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict results of Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.24 ms\n"
     ]
    }
   ],
   "source": [
    "xgb = make_pipeline(\n",
    "            preproc_ohe, \n",
    "            GridSearchCV(\n",
    "                XGBRegressor(),\n",
    "                param_grid = {'n_estimators' : [30, 100, 300, 800],\n",
    "                                        'max_depth' : [ 3, 5, 7] },\n",
    "                cv = 5,\n",
    "                verbose = 1,\n",
    "                error_score = \"neg_mean_squared_error\"\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pipeline', Pipeline(steps=[('dropcolumnswithmissingdata', DropColumnsWithMissingData(thresholds=0.9)), ('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('select_features', select_features(features=Index(['MSZoning', 'Street', 'LotShape', 'LandC...     pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1))])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90933699412817404"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.2 ms\n"
     ]
    }
   ],
   "source": [
    "xgb.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22273.077012616151"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.4 ms\n"
     ]
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(Ytest, xgb.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
