{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dodoml.pipeline import (\n",
    "    ColumnsSelector, UniqueCountColumnSelector, TolerantLabelEncoder, FillNaN,\n",
    "    ColumnApplier, OrdinalEncoder, CountFrequencyEncoder, Logify, BoxCoxTransformer,\n",
    "    YToLog)\n",
    "from dodoml import compute_features_impact, compute_partial_dependence, lift_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "from dodoml import compute_ace\n",
    "import sys\n",
    "sys.path.append(\"../../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gini function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gini metric - from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "# Create an XGBoost-compatible metric from Gini\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score\n",
    "    \n",
    "# We drop these variables as we don't want to train on them\n",
    "# The other 57 columns are all numerical and can be trained on without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dimension(train, test):\n",
    "    '''\n",
    "    check if number of columns in train set == number of columns in test set\n",
    "    '''\n",
    "    if (train.shape[1] == test.shape[1]):\n",
    "        return True\n",
    "    else:\n",
    "        print ('shape of train:', train.shape)\n",
    "        print ('shape of test:', test.shape)\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funtions adding features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (595212, 59)\n",
      "Test shape: (892816, 58)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_train = train['id'].values\n",
    "y = train.target.values\n",
    "id_test = test['id'].values\n",
    "\n",
    "#train['ps_ind_sum_bin'] = train[BIN].sum(axis = 1 )\n",
    "#train['ps_reg_mult'] = train.ps_reg_01 * train.ps_reg_02 * train.ps_reg_03\n",
    "#train['ps_car_13_ps_reg_03']= train.ps_car_13* train.ps_reg_03\n",
    "train['ps_car_15'] = (train.ps_car_15)**2\n",
    "train['ps_car_14'] = (train.ps_car_14)**2\n",
    "train['ps_car_12'] = round((train.ps_car_12)**2,4) * 10000\n",
    "train['ps_car_13'] = (train.ps_car_13)**2 * 48400\n",
    "train['ps_reg_03'] = (4*train.ps_reg_03)**2\n",
    "\n",
    "#test['ps_ind_sum_bin'] = test[BIN].sum(axis = 1 )\n",
    "#test['ps_reg_mult'] = test.ps_reg_01 * test.ps_reg_02 * test.ps_reg_03\n",
    "#test['ps_car_13_ps_reg_03']= test.ps_car_13* test.ps_reg_03\n",
    "test['ps_car_15'] = (test.ps_car_15)**2\n",
    "test['ps_car_14'] = (test.ps_car_14)**2\n",
    "test['ps_car_12'] = round((test.ps_car_12)**2,4) * 10000\n",
    "test['ps_car_13'] = (test.ps_car_13)**2 * 48400\n",
    "test['ps_reg_03'] = (4*test.ps_reg_03)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['id', 'ps_calc_10', 'ps_calc_01', 'ps_calc_04', 'ps_car_02_cat', 'ps_calc_14',\n",
    "               'ps_calc_08', 'ps_calc_17_bin', 'ps_car_10_cat', 'ps_ind_11_bin', 'ps_calc_12',\n",
    "               'ps_calc_09', 'ps_car_06_cat', 'ps_calc_05','ps_calc_16_bin', 'ps_calc_20_bin',\n",
    "                'ps_calc_18_bin']\n",
    "\n",
    "train.drop(drop_columns, axis = 1, inplace = True)\n",
    "train.drop('target', axis = 1, inplace = True)\n",
    "test.drop(drop_columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE with get_numpies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = []\n",
    "for col in train.columns:\n",
    "    if 'cat' in col:\n",
    "        CAT.append(col)\n",
    "        \n",
    "BIN = []\n",
    "for col in train.columns:\n",
    "    if 'bin' in col:\n",
    "        BIN.append(col)\n",
    "        \n",
    "CALC = []\n",
    "for col in train.columns:\n",
    "    if 'calc' in col:\n",
    "        CALC.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "for col in CAT:\n",
    "    data = pd.concat((data, pd.get_dummies(data[col], prefix=col)), axis=1)\n",
    "    data.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:train.shape[0],:]\n",
    "test = data.iloc[train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index = range(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_dimension(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 190)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = np.zeros_like(id_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Beginning Fold 1/5 ------------------\n",
      "[0]\ttrain-auc:0.607515\tvalid-auc:0.604684\ttrain-gini:0.214695\tvalid-gini:0.209841\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.631212\tvalid-auc:0.623651\ttrain-gini:0.262424\tvalid-gini:0.247304\n",
      "[200]\ttrain-auc:0.648701\tvalid-auc:0.631466\ttrain-gini:0.297402\tvalid-gini:0.262931\n",
      "[300]\ttrain-auc:0.662035\tvalid-auc:0.636979\ttrain-gini:0.324071\tvalid-gini:0.273959\n",
      "[400]\ttrain-auc:0.672204\tvalid-auc:0.639461\ttrain-gini:0.344408\tvalid-gini:0.278923\n",
      "[500]\ttrain-auc:0.680473\tvalid-auc:0.640381\ttrain-gini:0.360945\tvalid-gini:0.280762\n",
      "[600]\ttrain-auc:0.687634\tvalid-auc:0.640669\ttrain-gini:0.375269\tvalid-gini:0.281338\n",
      "[700]\ttrain-auc:0.693963\tvalid-auc:0.641112\ttrain-gini:0.387926\tvalid-gini:0.282223\n",
      "Stopping. Best iteration:\n",
      "[685]\ttrain-auc:0.693056\tvalid-auc:0.641116\ttrain-gini:0.386113\tvalid-gini:0.282233\n",
      "\n",
      "------------------End Fold 1/5-------------------\n",
      "------------------Beginning Fold 2/5 ------------------\n",
      "[0]\ttrain-auc:0.608945\tvalid-auc:0.599634\ttrain-gini:0.217517\tvalid-gini:0.199883\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.630512\tvalid-auc:0.618656\ttrain-gini:0.261021\tvalid-gini:0.237313\n",
      "[200]\ttrain-auc:0.647993\tvalid-auc:0.630692\ttrain-gini:0.295985\tvalid-gini:0.261384\n",
      "[300]\ttrain-auc:0.662124\tvalid-auc:0.637321\ttrain-gini:0.324247\tvalid-gini:0.274642\n",
      "[400]\ttrain-auc:0.672216\tvalid-auc:0.640166\ttrain-gini:0.344432\tvalid-gini:0.280332\n",
      "[500]\ttrain-auc:0.680424\tvalid-auc:0.6414\ttrain-gini:0.360847\tvalid-gini:0.2828\n",
      "[600]\ttrain-auc:0.68771\tvalid-auc:0.641914\ttrain-gini:0.375419\tvalid-gini:0.283828\n",
      "[700]\ttrain-auc:0.694254\tvalid-auc:0.642043\ttrain-gini:0.388509\tvalid-gini:0.284085\n",
      "Stopping. Best iteration:\n",
      "[686]\ttrain-auc:0.693285\tvalid-auc:0.642115\ttrain-gini:0.386571\tvalid-gini:0.28423\n",
      "\n",
      "------------------End Fold 2/5-------------------\n",
      "------------------Beginning Fold 3/5 ------------------\n",
      "[0]\ttrain-auc:0.607489\tvalid-auc:0.604219\ttrain-gini:0.214334\tvalid-gini:0.207668\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.630134\tvalid-auc:0.62462\ttrain-gini:0.260269\tvalid-gini:0.249235\n",
      "[200]\ttrain-auc:0.64901\tvalid-auc:0.634675\ttrain-gini:0.298019\tvalid-gini:0.26935\n",
      "[300]\ttrain-auc:0.662716\tvalid-auc:0.63995\ttrain-gini:0.325433\tvalid-gini:0.279899\n",
      "[400]\ttrain-auc:0.672812\tvalid-auc:0.641775\ttrain-gini:0.345624\tvalid-gini:0.28355\n",
      "[500]\ttrain-auc:0.680442\tvalid-auc:0.642695\ttrain-gini:0.360885\tvalid-gini:0.285391\n",
      "[600]\ttrain-auc:0.687632\tvalid-auc:0.642699\ttrain-gini:0.375264\tvalid-gini:0.285398\n",
      "Stopping. Best iteration:\n",
      "[540]\ttrain-auc:0.683359\tvalid-auc:0.642886\ttrain-gini:0.366718\tvalid-gini:0.285772\n",
      "\n",
      "------------------End Fold 3/5-------------------\n",
      "------------------Beginning Fold 4/5 ------------------\n",
      "[0]\ttrain-auc:0.610068\tvalid-auc:0.605267\ttrain-gini:0.219987\tvalid-gini:0.209246\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.630119\tvalid-auc:0.620874\ttrain-gini:0.260238\tvalid-gini:0.241745\n",
      "[200]\ttrain-auc:0.64665\tvalid-auc:0.632333\ttrain-gini:0.293301\tvalid-gini:0.264665\n"
     ]
    }
   ],
   "source": [
    "X = train.values\n",
    "x_test = test.values\n",
    "xgbscores = []\n",
    "\n",
    "# Set xgb parameters\n",
    "\n",
    "params = {'eta': 0.02, 'max_depth': 5, 'subsample': 0.9, 'colsample_bytree':\n",
    "      0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent':\n",
    "      True, 'tree_method' : 'exact'}\n",
    "\n",
    "kfold = 5\n",
    "sss = StratifiedKFold(n_splits=kfold, random_state=0)\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    print('------------------Beginning Fold %d/%d ------------------' % (i + 1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    d_test = xgb.DMatrix(x_test)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    mdl = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=100, \n",
    "                    feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "\n",
    "    print('------------------End Fold %d/%d-------------------' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test = mdl.predict(d_test)\n",
    "    sub['target'] += p_test/kfold\n",
    "\n",
    "sub.to_csv('xgb3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "#from numba import jit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This simple scripts demonstrates the use of xgboost eval results to get the best round\n",
    "for the current fold and accross folds. \n",
    "It also shows an upsampling method that limits cross-validation overfitting.\n",
    "\"\"\"\n",
    "\n",
    "def eval_gini(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Original author CPMP : https://www.kaggle.com/cpmpml\n",
    "    In kernel : https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "\n",
    "def target_encode(trn_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by= trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0"
     ]
    }
   ],
   "source": [
    "gc.enable()\n",
    "\n",
    "trn_df = pd.read_csv(\"data/train.csv\", index_col=0)\n",
    "sub_df = pd.read_csv(\"data/test.csv\", index_col=0)\n",
    "\n",
    "target = trn_df[\"target\"]\n",
    "trn_df.drop(\"target\", axis =1, inplace = True)\n",
    "\n",
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "     \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "     \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "     \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "     \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "     \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "     \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "     \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "     \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "     \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "     \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "     \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "     \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "     \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "     \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "     \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "     \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    trn_df[name1] = trn_df[f1].apply(lambda x: str(x)) + \"_\" + trn_df[f2].apply(lambda x: str(x))\n",
    "    sub_df[name1] = sub_df[f1].apply(lambda x: str(x)) + \"_\" + sub_df[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(trn_df[name1].values) + list(sub_df[name1].values))\n",
    "    trn_df[name1] = lbl.transform(list(trn_df[name1].values))\n",
    "    sub_df[name1] = lbl.transform(list(sub_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "\n",
    "trn_df = trn_df[train_features]\n",
    "sub_df = sub_df[train_features]\n",
    "\n",
    "f_cats = [f for f in trn_df.columns if \"_cat\" in f]\n",
    "\n",
    "for f in f_cats:\n",
    "    trn_df[f + \"_avg\"], sub_df[f + \"_avg\"] = target_encode(trn_series=trn_df[f],\n",
    "                                         tst_series=sub_df[f],\n",
    "                                         target=target,\n",
    "                                         min_samples_leaf=200,\n",
    "                                         smoothing=10,\n",
    "                                         noise_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 : 0.287436 @ 200 / best score is 0.287500 @ 176\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "n_estimators = 200\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=15) \n",
    "imp_df = np.zeros((len(trn_df.columns), n_splits))\n",
    "xgb_evals = np.zeros((n_estimators, n_splits))\n",
    "oof = np.empty(len(trn_df))\n",
    "sub_preds = np.zeros(len(sub_df))\n",
    "increase = True\n",
    "np.random.seed(0)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(target, target)):\n",
    "    trn_dat, trn_tgt = trn_df.iloc[trn_idx], target.iloc[trn_idx]\n",
    "    val_dat, val_tgt = trn_df.iloc[val_idx], target.iloc[val_idx]\n",
    "\n",
    "    clf = XGBClassifier(n_estimators=n_estimators,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1, \n",
    "                        subsample=.8, \n",
    "                        colsample_bytree=.8,\n",
    "                        gamma=1,\n",
    "                        reg_alpha=0,\n",
    "                        reg_lambda=1,\n",
    "                        nthread=2)\n",
    "    # Upsample during cross validation to avoid having the same samples\n",
    "    # in both train and validation sets\n",
    "    # Validation set is not up-sampled to monitor overfitting\n",
    "    if increase:\n",
    "        # Get positive examples\n",
    "        pos = pd.Series(trn_tgt == 1)\n",
    "        # Add positive examples\n",
    "        trn_dat = pd.concat([trn_dat, trn_dat.loc[pos]], axis=0)\n",
    "        trn_tgt = pd.concat([trn_tgt, trn_tgt.loc[pos]], axis=0)\n",
    "        # Shuffle data\n",
    "        idx = np.arange(len(trn_dat))\n",
    "        np.random.shuffle(idx)\n",
    "        trn_dat = trn_dat.iloc[idx]\n",
    "        trn_tgt = trn_tgt.iloc[idx]\n",
    "        \n",
    "    clf.fit(trn_dat, trn_tgt, \n",
    "            eval_set=[(trn_dat, trn_tgt), (val_dat, val_tgt)],\n",
    "            eval_metric=gini_xgb,\n",
    "            early_stopping_rounds=None,\n",
    "            verbose=False)\n",
    "            \n",
    "    # Keep feature importances\n",
    "    imp_df[:, fold_] = clf.feature_importances_\n",
    "\n",
    "    # Find best round for validation set\n",
    "    xgb_evals[:, fold_] = clf.evals_result_[\"validation_1\"][\"gini\"]\n",
    "    # Xgboost provides best round starting from 0 so it has to be incremented\n",
    "    best_round = np.argsort(xgb_evals[:, fold_])[::-1][0]\n",
    "\n",
    "    # Predict OOF and submission probas with the best round\n",
    "    oof[val_idx] = clf.predict_proba(val_dat, ntree_limit=best_round)[:, 1]\n",
    "    # Update submission\n",
    "    sub_preds += clf.predict_proba(sub_df, ntree_limit=best_round)[:, 1] / n_splits\n",
    "\n",
    "    # Display results\n",
    "    print(\"Fold %2d : %.6f @%4d / best score is %.6f @%4d\"\n",
    "          % (fold_ + 1,\n",
    "             eval_gini(val_tgt, oof[val_idx]),\n",
    "             n_estimators,\n",
    "             xgb_evals[best_round, fold_],\n",
    "             best_round))\n",
    "          \n",
    "print(\"Full OOF score : %.6f\" % eval_gini(target, oof))\n",
    "\n",
    "# Compute mean score and std\n",
    "mean_eval = np.mean(xgb_evals, axis=1)\n",
    "std_eval = np.std(xgb_evals, axis=1)\n",
    "best_round = np.argsort(mean_eval)[::-1][0]\n",
    "\n",
    "print(\"Best mean score : %.6f + %.6f @%4d\"\n",
    "      % (mean_eval[best_round], std_eval[best_round], best_round))\n",
    "    \n",
    "importances = sorted([(trn_df.columns[i], imp) for i, imp in enumerate(imp_df.mean(axis=1))],\n",
    "                     key=lambda x: x[1])\n",
    "\n",
    "for f, imp in importances[::-1]:\n",
    "    print(\"%-34s : %10.4f\" % (f, imp))\n",
    "    \n",
    "sub_df[\"target\"] = sub_preds\n",
    "\n",
    "sub_df[[\"target\"]].to_csv(\"submission.csv\", index=True, float_format=\"%.9f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Beginning Fold 1/5 ------------------\n",
      "[0]\ttrain-auc:0.609307\tvalid-auc:0.607336\ttrain-gini:0.218241\tvalid-gini:0.214305\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.635054\tvalid-auc:0.626248\ttrain-gini:0.270107\tvalid-gini:0.252498\n",
      "[200]\ttrain-auc:0.651116\tvalid-auc:0.634765\ttrain-gini:0.302231\tvalid-gini:0.269529\n",
      "[300]\ttrain-auc:0.662976\tvalid-auc:0.639395\ttrain-gini:0.325951\tvalid-gini:0.27879\n",
      "[400]\ttrain-auc:0.672253\tvalid-auc:0.641786\ttrain-gini:0.344506\tvalid-gini:0.283572\n",
      "[500]\ttrain-auc:0.679386\tvalid-auc:0.642935\ttrain-gini:0.358773\tvalid-gini:0.285871\n",
      "[600]\ttrain-auc:0.685309\tvalid-auc:0.643074\ttrain-gini:0.370619\tvalid-gini:0.286148\n",
      "[700]\ttrain-auc:0.690722\tvalid-auc:0.643379\ttrain-gini:0.381445\tvalid-gini:0.286758\n",
      "[800]\ttrain-auc:0.695842\tvalid-auc:0.64324\ttrain-gini:0.391684\tvalid-gini:0.28648\n",
      "Stopping. Best iteration:\n",
      "[736]\ttrain-auc:0.692538\tvalid-auc:0.643448\ttrain-gini:0.385075\tvalid-gini:0.286896\n",
      "\n",
      "------------------End Fold 1/5-------------------\n",
      "------------------Beginning Fold 2/5 ------------------\n",
      "[0]\ttrain-auc:0.609764\tvalid-auc:0.60812\ttrain-gini:0.219023\tvalid-gini:0.216401\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.636046\tvalid-auc:0.623931\ttrain-gini:0.272092\tvalid-gini:0.247862\n",
      "[200]\ttrain-auc:0.651257\tvalid-auc:0.632134\ttrain-gini:0.302514\tvalid-gini:0.264267\n",
      "[300]\ttrain-auc:0.663055\tvalid-auc:0.637529\ttrain-gini:0.326109\tvalid-gini:0.275057\n",
      "[400]\ttrain-auc:0.672712\tvalid-auc:0.64042\ttrain-gini:0.345424\tvalid-gini:0.28084\n",
      "[500]\ttrain-auc:0.679541\tvalid-auc:0.641291\ttrain-gini:0.359081\tvalid-gini:0.282583\n",
      "[600]\ttrain-auc:0.685398\tvalid-auc:0.641981\ttrain-gini:0.370797\tvalid-gini:0.283963\n",
      "[700]\ttrain-auc:0.690932\tvalid-auc:0.642042\ttrain-gini:0.381864\tvalid-gini:0.284085\n",
      "Stopping. Best iteration:\n",
      "[673]\ttrain-auc:0.689516\tvalid-auc:0.642188\ttrain-gini:0.379032\tvalid-gini:0.284375\n",
      "\n",
      "------------------End Fold 2/5-------------------\n",
      "------------------Beginning Fold 3/5 ------------------\n",
      "[0]\ttrain-auc:0.609608\tvalid-auc:0.605276\ttrain-gini:0.218322\tvalid-gini:0.209035\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-auc:0.634816\tvalid-auc:0.627166\ttrain-gini:0.269632\tvalid-gini:0.25433\n",
      "[200]\ttrain-auc:0.651841\tvalid-auc:0.637032\ttrain-gini:0.303681\tvalid-gini:0.274064\n",
      "[300]\ttrain-auc:0.663469\tvalid-auc:0.640874\ttrain-gini:0.326939\tvalid-gini:0.281748\n",
      "[400]\ttrain-auc:0.672557\tvalid-auc:0.643181\ttrain-gini:0.345114\tvalid-gini:0.286362\n"
     ]
    }
   ],
   "source": [
    "# Create a submission file\n",
    "import xgboost as xgb\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = np.zeros_like(id_test)\n",
    "\n",
    "X = trn_df.values\n",
    "x_test = sub_df.values\n",
    "xgbscores = []\n",
    "\n",
    "# Set xgb parameters\n",
    "\n",
    "params = {'eta': 0.02, 'max_depth': 5, 'subsample': 0.9, 'colsample_bytree':\n",
    "      0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent':\n",
    "      True, 'tree_method' : 'exact'}\n",
    "\n",
    "kfold = 5\n",
    "sss = StratifiedKFold(n_splits=kfold, random_state=0)\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    print('------------------Beginning Fold %d/%d ------------------' % (i + 1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    d_test = xgb.DMatrix(x_test)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    mdl = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=100, \n",
    "                    feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "\n",
    "    print('------------------End Fold %d/%d-------------------' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test = mdl.predict(d_test)\n",
    "    sub['target'] += p_test/kfold\n",
    "\n",
    "sub.to_csv('xgb3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
