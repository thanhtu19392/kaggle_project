{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-15c8cd5714a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn import clone\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import log_loss\n",
    "import pickle\n",
    "import random\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X_train = train.ix[:, train.columns != 'target']\n",
    "y_train = train.ix[:, train.columns == 'target']\n",
    "\n",
    "test_id = test['ID']\n",
    "\n",
    "X_train = X_train.drop('ID', axis =1)\n",
    "X_test_w = test.drop('ID', axis =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training set and test set into 2 part for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(n_estimators=2000,learning_rate=0.03, one_hot_max_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-48a2aac41443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/env36/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, plot)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mCatBoost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[0;32m--> 929\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env36/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, plot)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has not initialized in fit(): X is not Pool object, y must be not None in fit().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'use_best_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env36/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, column_description, delimiter, has_header, weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env36/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data_matrix, label, cat_features, weight, baseline, feature_names)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool (/home/rnefyodov/.ya/build/build_root/676e74667a3979746c773265657a6d73/catboost/python-package/catboost/_catboost.pyx.cpp:5141)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool (/home/rnefyodov/.ya/build/build_root/676e74667a3979746c773265657a6d73/catboost/python-package/catboost/_catboost.pyx.cpp:4860)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._set_data (/home/rnefyodov/.ya/build/build_root/676e74667a3979746c773265657a6d73/catboost/python-package/catboost/_catboost.pyx.cpp:5586)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'C'"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = X_train.select_dtypes(include=[\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['v3', 'v22', 'v24', 'v30', 'v31', 'v47', 'v52', 'v56', 'v66', 'v71',\n",
       "       'v74', 'v75', 'v79', 'v91', 'v107', 'v110', 'v112', 'v113', 'v125'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.unique(X_train[['v22']].fillna('nan'), return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c22 = pd.DataFrame({ 'values' : a[0], 'counts' : a[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_91_107 = pd.get_dummies(X_train[['v91', 'v107']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa34017e3c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJeCAYAAAB29ktyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlbCwIiIiIlLJ/6ypweWpGZgIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa33ff4ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrMatrix = df_91_107.corr()\n",
    "sns.set(font_scale = 1.1)\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(corrMatrix, vmax =.8, linewidths = 0.01, cmap ='viridis', linecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v91</th>\n",
       "      <th>v107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(A, E), (B, B), (C, D), (D, G), (E, F), (F, A), (G, C)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['v91', 'v107']].groupby(['v91', 'v107']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v75</th>\n",
       "      <th>v71</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">B</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">C</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">D</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(A, B), (A, C), (A, F), (A, G), (A, I), (A, K), (B, B), (B, C), (B, F), (C, B), (C, C), (C, F), (C, I), (D, C), (D, F)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['v71', 'v75']].groupby(['v75', 'v71' ]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop all columns which have percentage of missing values superior 40%\n",
    "class DropColumnsWithMissingData(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, thresholds=0.40):\n",
    "        self.thresholds = thresholds\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        a = X.isnull().mean()\n",
    "        self.kept_columns = a.index[a < self.thresholds].tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.kept_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class addFeatures:\n",
    "    \n",
    "    def __init__(self, n_neighbours=1, max_elts=None):\n",
    "        \"\"\"\n",
    "        add variables which compose 3 features existants giving the highest score of linear regression \n",
    "        \n",
    "        n_neighbours: Number of features to add\n",
    "        max_elts: Maximum size of a group of linear features\n",
    "        \"\"\"\n",
    "        self.n = n_neighbours\n",
    "        self.max_elts = max_elts\n",
    "        self.neighbours = []\n",
    "        self.clfs = []\n",
    "        \n",
    "    def fit(self,X, y):\n",
    "        if self.max_elts == None:\n",
    "            self.max_elts = len(X.columns)\n",
    "        list_vars = list(X.columns)\n",
    "        random.shuffle(list_vars)\n",
    "        \n",
    "        lastscores = np.zeros(self.n) + 1e15\n",
    "\n",
    "        for elt in list_vars[:self.n]:\n",
    "            self.neighbours.append([elt])\n",
    "        list_vars = list_vars[self.n:]\n",
    "        \n",
    "        for elt in list_vars:\n",
    "            indice = 0\n",
    "            scores = []\n",
    "            for elt2 in self.neighbours:\n",
    "                if len(elt2) < self.max_elts:\n",
    "                    clf = LinearRegression(fit_intercept=False, normalize=True, copy_X=True, n_jobs=-1) \n",
    "                    clf.fit(X[elt2 + [elt]], y)\n",
    "                    scores.append(log_loss(y,clf.predict(X[elt2 + [elt]])))\n",
    "                    indice = indice + 1\n",
    "                else:\n",
    "                    scores.append(lastscores[indice])\n",
    "                    indice = indice + 1\n",
    "            gains = lastscores - scores\n",
    "            if gains.max() > 0:\n",
    "                temp = gains.argmax()\n",
    "                lastscores[temp] = scores[temp]\n",
    "                self.neighbours[temp].append(elt)\n",
    "\n",
    "        indice = 0\n",
    "        for elt in self.neighbours:\n",
    "            clf = LinearRegression(fit_intercept=False, normalize=True, copy_X=True, n_jobs=-1) \n",
    "            clf.fit(X[elt], y)\n",
    "            self.clfs.append(clf)\n",
    "            indice = indice + 1\n",
    "                    \n",
    "    def transform(self, X):\n",
    "        indice = 0\n",
    "        for elt in self.neighbours:\n",
    "            X['_'.join(pd.Series(elt).sort_values().values)] = self.clfs[indice].predict(X[elt])\n",
    "            indice = indice + 1\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-7423ba4f4f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maddNearestNeighbourLinearFeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "addNearestNeighbourLinearFeatures.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DropColumnsCorrelated(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self, ListColumns):\n",
    "        self.listcolumns = ListColumns\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(self.listcolumns , axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_n = DropColumnsWithMissingData(thresholds=0.40).fit_transform(X_train)\n",
    "#ListColumns = ['v107']\n",
    "#X_train_n = DropColumnsCorrelated(ListColumns).fit_transform(X_train_n)\n",
    "\n",
    "categorical_features = X_train_n.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_features = X_train_n.select_dtypes(exclude=[\"object\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class select_features(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Select categorical features or numerical features \n",
    "    \"\"\"\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "         \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.features]\n",
    "\n",
    "    \n",
    "class FillMissingValues(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Fill missing values \n",
    "    'nan' for categorical features\n",
    "    or -999 for numerical features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, replace_value):\n",
    "        self.replace_value = replace_value\n",
    "        # replace_value = 'nan' for filling missing data in categorical features\n",
    "        # or -999 in numerical features\n",
    "       \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.replace_value)\n",
    "    \n",
    "    \n",
    "class ColumnApplier(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Some sklearn transformers can apply only on ONE column at a time (such as LabelEnconder())\n",
    "    Wrap them with ColumnApplier to apply on all columns in the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, underlying):\n",
    "        self.underlying = underlying\n",
    "        #TODO: underlying is one model method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        m = {}\n",
    "        X = pd.DataFrame(X)  # TODO: :( reimplement in pure numpy?\n",
    "        for c in X.columns:\n",
    "            k = clone(self.underlying) \n",
    "            #TODO: clone helps to construct a new estimator with the same parameters.\n",
    "            #      deep copy of the model in an estimator without actually copying attached data\n",
    "            \n",
    "            k.fit(X[c])\n",
    "            # fit model k for every column in X \n",
    "            \n",
    "            m[c] = k\n",
    "            # put it in dictionary with column c as key and k as items\n",
    "        \n",
    "        self._column_stages = m\n",
    "        # self.column_stages is a dictionary with column c in X as key and model k.fit as items \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        ret = {}\n",
    "        X = pd.DataFrame(X)\n",
    "        for c, k in self._column_stages.items():\n",
    "            ret[c] = k.transform(X[c])\n",
    "            # ret is a dict which has c as key and k.transform as items\n",
    "        return pd.DataFrame(ret)[X.columns]  # keep the same order\n",
    "\n",
    "class TolerantLabelEncoder(LabelEncoder):\n",
    "    \"\"\"\n",
    "    LabelEncoder is not tolerant to unseen values\n",
    "    \"\"\"\n",
    "    def transform(self, y):\n",
    "        return np.searchsorted(self.classes_, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreatmentSpecialColumns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column = 'v22', threshold = 50):\n",
    "        self.column = column\n",
    "        self.threshold = threshold \n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        X_col=X[self.column].fillna('nan')\n",
    "        values, counts = np.unique(X_col ,return_counts=True)\n",
    "        counts = {x : y for x, y in zip(values, counts)}\n",
    "        X[self.column] = X[self.column].apply(lambda x: x if counts.get(x, 0) > self.threshold else 0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b05b2be8d53a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Label Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m preproc_le = make_pipeline (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mDropColumnsWithMissingData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#TreatmentSpecialColumns(column = 'v22', threshold = 50),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#DropColumnsCorrelated(ListColumns = ['v107']),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "preproc_le = make_pipeline (\n",
    "    DropColumnsWithMissingData(thresholds=0.40),\n",
    "    #TreatmentSpecialColumns(column = 'v22', threshold = 50),\n",
    "    #DropColumnsCorrelated(ListColumns = ['v107']),\n",
    "    addNearestNeighbourLinearFeatures(n_neighbours=20, max_elts=3, verbose=True, random_state=1),\n",
    "    make_union(make_pipeline(\n",
    "        select_features(categorical_features),\n",
    "        FillMissingValues('nan'),\n",
    "        ColumnApplier(TolerantLabelEncoder())\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        select_features(numerical_features),\n",
    "        FillMissingValues(-999),\n",
    "        StandardScaler()\n",
    "        \n",
    "    )\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot Encoding\n",
    "preproc_ohe = make_pipeline (\n",
    "    \n",
    "    DropColumnsWithMissingData(thresholds=0.40),\n",
    "    #TreatmentSpecialColumns(column = 'v22', threshold = 50),\n",
    "    #DropColumnsCorrelated(ListColumns = ['v91']),\n",
    "    make_union(\n",
    "    make_pipeline(\n",
    "        select_features(categorical_features),\n",
    "        FillMissingValues('nan'),\n",
    "        ColumnApplier(TolerantLabelEncoder()),\n",
    "        OneHotEncoder(handle_unknown = 'ignore')\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        select_features(numerical_features),\n",
    "        FillMissingValues(-999),\n",
    "        StandardScaler()        \n",
    "    )\n",
    "  ),\n",
    "    addNearestNeighbourLinearFeatures(n_neighbours=20, max_elts=3, verbose=True, random_state=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "columns not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-89354e53280e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreproc_ohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-a442b11c5ae3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_elts\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_elts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlist_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env36/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: columns not found"
     ]
    }
   ],
   "source": [
    "preproc_ohe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackedModel(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Stacking models\n",
    "    \"\"\"\n",
    "    def __init__(self, delegate):\n",
    "        self.delegate = delegate\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        a = cross_val_predict(self.delegate, X, y, cv= 5, method = 'predict_proba')\n",
    "        # Generate cross-validated estimates for each input data point\n",
    "        self.delegate.fit(X, y)\n",
    "        return a[:,1:]\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.delegate.predict_proba(X)[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-33e5d75b6a4a>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-33e5d75b6a4a>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    score =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class KeepBestOnly(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, delegates):\n",
    "        self.delegates = delegates\n",
    "\n",
    "    def fit_transorm(self, X, y):\n",
    "        list_model = []\n",
    "        list_score = []\n",
    "        for model in self.delegates:\n",
    "            model.fit(X, y)\n",
    "            model.predict_proba(X)[:, 1]\n",
    "            score = model\n",
    "            list_model.append({score : model})\n",
    "            list_score.append(score)\n",
    "        \n",
    "        max_score = \n",
    "        self.best_model = list_model[max]\n",
    "        return best_prediction  # 1D\n",
    "        \n",
    "    def transform(self, X):\n",
    "        \n",
    "        return self.best_model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    preproc_ohe,\n",
    "    make_union(\n",
    "        make_pipeline(\n",
    "            KeepBestOnly([\n",
    "                XGBClassifier(n_estimators=100),\n",
    "                XGBClassifier(n_estimators=800),\n",
    "                XGBClassifier(n_estimators = 1000)\n",
    "            ]),\n",
    "            StackedModel(),\n",
    "    ),\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train_n)\n",
    "mode.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_n = y_train['target'].values\n",
    "skf = list(StratifiedKFold(y_train_n, n_folds= 5, shuffle=True, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BestParams(X_train, y_train_n, preproc, clfs, skf):\n",
    "    ListModel = {}\n",
    "    for clf, params in clfs.items():\n",
    "        pipeline = make_pipeline(\n",
    "            preproc, \n",
    "            GridSearchCV(\n",
    "                clf,\n",
    "                params,\n",
    "                cv = skf,\n",
    "                verbose= 1, \n",
    "                scoring='log_loss'\n",
    "                )\n",
    "            )\n",
    "        pipeline.fit(X_train, y_train_n)\n",
    "        ListModel[clf] = pipeline\n",
    "    return ListModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    {'clf': XGBClassifier(),\n",
    "     'params': {\n",
    "        'n_estimators' : [30, 100, 300, 800],\n",
    "         'max_depth' : [ 3, 5, 7] \n",
    "            }\n",
    "    },\n",
    "    {'clf': ExtraTreesClassifier(),\n",
    "     'params': {\n",
    "        'n_estimators' : [30, 100, 300, 800],\n",
    "        'criterion' : ('gini', 'entropy'),\n",
    "        'max_depth' : [3, 5, 7]\n",
    "            }\n",
    "    },\n",
    "    {'clf': RandomForestClassifier(),\n",
    "     'params': {\n",
    "        'n_estimators' : [30, 100, 300, 800],\n",
    "         'criterion' : ('gini', 'entropy'),\n",
    "         'max_depth' : [ 3, 5, 7] \n",
    "            }\n",
    "    },\n",
    "    {'clf':  LogisticRegression(),\n",
    "     'params': {\n",
    "        'C' : [0.05, 0.1 , 1, 10], \n",
    "        'penalty' : ('l2', 'l1')\n",
    "            }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "pipe_label = BestParams(X_train, y_train_n, preproc_label, clfs, skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_xgb = pipe_label[list(clfs)[0]].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = pickle.load(open('pipeline_xgb.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_le = xgb.steps[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'n_estimators': 100}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_le.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_xgb = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46646328202720494"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_xg = log_loss(y_test, y_predict_xgb[:,1:])\n",
    "score_xg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_et = pipe_label[list(clfs)[1]].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et = pickle.load(open('pipeline_et.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 7, 'n_estimators': 100}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_le = et.steps[-1][1]\n",
    "et_le.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_et = et.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51067415633793001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_et = log_loss(y_test, y_predict_et[:,1:])\n",
    "score_et"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_lg = pipe_label[list(clfs)[1]].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg = pickle.load(open('pipeline_lg.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_le = lg.steps[-1][1]\n",
    "lg_le.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_lg = lg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48589723267040652"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_lg = log_loss(y_test, y_predict_lg[:,1:])\n",
    "score_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_ohe = BestParamsModel(X_train, y_train_n, preproc_ohe, clfs, skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_xgb = pipe_ohe[list(clfs)[0]].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_ohe = pickle.load(open('xgb_ohe.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ohe.steps[-1][1].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46675254991029314"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ohe_xgb = xgb_ohe.predict_proba(X_test)\n",
    "\n",
    "score_xgb_ohe = log_loss(y_test, y_ohe_xgb[:,1:])\n",
    "score_xgb_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_et = pipe_ohe[list(clfs)[1]].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_lg = pipe_ohe[list(clfs)[2]].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46646328202720494"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_score = min(score_xg, score_et, score_lg, score_xgb_ohe)\n",
    "min_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FinalModel = make_pipeline(\n",
    "     make_union(\n",
    "        make_pipeline(\n",
    "        preproc_le,\n",
    "            make_union(\n",
    "                StackedModel(XGBClassifier(n_estimators = 100, max_depth = 7)),\n",
    "                StackedModel(ExtraTreesClassifier(criterion= 'gini', max_depth = 7, n_estimators = 100)),\n",
    "                StackedModel(LogisticRegression(C = 0.1, penalty = 'l1'))\n",
    "            )\n",
    "        ),\n",
    "         make_pipeline(\n",
    "         preproc_ohe,\n",
    "             make_union(\n",
    "                StackedModel(XGBClassifier(learning_rate = 0.1, max_depth = 5, n_estimators = 100)),\n",
    "                StackedModel(ExtraTreesClassifier(criterion= 'gini', max_depth = 7, n_estimators = 100)),\n",
    "                StackedModel(LogisticRegression(C = 0.1, penalty = 'l1'))\n",
    "            )\n",
    "        )\n",
    "     ),\n",
    "    XGBClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('pipeline', Pipeline(steps=[('dropcolumnswithmissingdata', DropColumnsWithMissingData(thresholds=0.4)), ('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(ste...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalModel.fit(X_train, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46514788342566055"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction_last = FinalModel.predict_proba(X_test)\n",
    "score = log_loss(y_test, y_prediction_last[:,1:])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
