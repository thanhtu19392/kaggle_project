{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using make_pipeline and make_union in Sklearn\n",
    "**Transformer** in scikit-learn - some class that have fit and transform method, or fit_transform method.\n",
    "\n",
    "**Predictor** - some class that has fit and predict methods, or fit_predict method.\n",
    "\n",
    "**Pipeline** is just an abstract notion, it's not some existing ml algorithm. Often in ML tasks you need to perform sequence of different transformations (find set of features, generate new features, select only some good features) of raw dataset before applying final estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn import clone\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  after removing the cwd from sys.path.\n",
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X_train = train.ix[:, train.columns != 'target']\n",
    "y_train = train.ix[:, train.columns == 'target']\n",
    "\n",
    "X_test = test.ix[:, test.columns != 'target']\n",
    "\n",
    "test_id = X_test['ID']\n",
    "\n",
    "X_train = X_train.drop('ID', axis =1)\n",
    "X_test = X_test.drop('ID', axis =1 )\n",
    "\n",
    "#categorical_features = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "#numerical_features = X_train.select_dtypes(exclude=[\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop all columns which have percentage of missing values superior 40%\n",
    "class DropColumnsWithMissingData(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, thresholds=0.40):\n",
    "        self.thresholds = thresholds\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        a = X.isnull().mean()\n",
    "        self.kept_columns = a.index[a < self.thresholds].tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.kept_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def factorize(train, test):\n",
    "    for (train_name, train_series), (test_name, test_series) in zip(train.items(), test.items()):\n",
    "        \n",
    "        #LabelEncoder \n",
    "        if train_series.dtype == 'O': #check if object\n",
    "            train[train_name], tmp_indexer = pd.factorize(train[train_name])\n",
    "            # pd.factorize will return, in second position, the list of unique values (or categorical labels) in the provided \n",
    "            # column, in first position, the indices that would let you recreate the original column from the unique values\n",
    "            \n",
    "            # train[train_name] will be replaced by its index-based representation, \n",
    "            # tmp_indexer will contains the unique values in the original train[train_name].\n",
    "\n",
    "            test[train_name] = tmp_indexer.get_indexer(test[train_name])\n",
    "            #  get_indexer will return the indices where the values in test[test_name] are to be found in tmp_indexer\n",
    "            #  the current test column is replaced by a list of indices in the exact same way the corresponding train column was in the line above.\n",
    "    return train, test\n",
    "\n",
    "def preprocess_data(train, test):\n",
    "    train = DropColumnsWithMissingData(thresholds=0.40).fit_transform(train)\n",
    "\n",
    "    columns_n = train.columns\n",
    "    X_test = test[columns_n]\n",
    "    \n",
    "    train, test = factorize(train, test)\n",
    "\n",
    "    return (train, test)\n",
    "\n",
    "X_train, X_test = preprocess_data(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_features = X_train.select_dtypes(exclude= ['object']).columns\n",
    "categorical_features = X_train_n.select_dtypes(include=[\"object\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select categorical features or numerical features \n",
    "class select_features(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "         \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.features]\n",
    "\n",
    "    \n",
    "class FillMissingValues(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, replace_value):\n",
    "        self.replace_value = replace_value\n",
    "        # replace_value = 'nan' for filling missing data in categorical features\n",
    "        # or -999 in numerical features\n",
    "       \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc = make_union(\n",
    "    make_pipeline (\n",
    "        select_features(numerical_features),\n",
    "        FillMissingValues(-999),\n",
    "        StandardScaler()\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        select_features(cate)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = make_pipeline(\n",
    "    preproc, \n",
    "    XGBClassifier(n_estimators=800)                  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_n, X_test_n, y_train_n, y_test = train_test_split( X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model1 = xgb.fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model1.predict_proba(X_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = model1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = log_loss(y_test, y_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46858837559110444"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"ID\": test_id, \"PredictedProb\": y_predict[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('predict_bnp_5.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTressClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext = make_pipeline(\n",
    "    preproc , \n",
    "    ExtraTreesClassifier(n_estimators = 800),  \n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/pipeline.py:270: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "model_ext = ext.fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred2 = model_ext.predict_proba(X_test_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47659111744476035"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = log_loss(y_test, y_pred2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) \n",
    "y_pred3 = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47964501495561412"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = log_loss(y_test, y_pred3)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import dump, load\n",
    "dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import dump, load\n",
    "\n",
    "dump(xgb, 'fitted/xgb.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
