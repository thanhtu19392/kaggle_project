{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using make_pipeline and make_union in Sklearn\n",
    "**Transformer** in scikit-learn - some class that have fit and transform method, or fit_transform method.\n",
    "\n",
    "**Predictor** - some class that has fit and predict methods, or fit_predict method.\n",
    "\n",
    "**Pipeline** is just an abstract notion, it's not some existing ml algorithm. Often in ML tasks you need to perform sequence of different transformations (find set of features, generate new features, select only some good features) of raw dataset before applying final estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn import clone\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X_train = train.ix[:, train.columns != 'target']\n",
    "y_train = train.ix[:, train.columns == 'target']\n",
    "\n",
    "test_id = test['ID']\n",
    "\n",
    "X_train = X_train.drop('ID', axis =1)\n",
    "X_test = test.drop('ID', axis =1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training set and test set into 2 part for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop all columns which have percentage of missing values superior 40%\n",
    "class DropColumnsWithMissingData(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, thresholds=0.40):\n",
    "        self.thresholds = thresholds\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        a = X.isnull().mean()\n",
    "        self.kept_columns = a.index[a < self.thresholds].tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.kept_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_n = DropColumnsWithMissingData(thresholds=0.40).fit_transform(X_train)\n",
    "\n",
    "categorical_features = X_train_n.select_dtypes(include=[\"object\"]).columns\n",
    "numerical_features = X_train_n.select_dtypes(exclude=[\"object\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select categorical features or numerical features \n",
    "class select_features(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "         \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.features]\n",
    "\n",
    "    \n",
    "class FillMissingValues(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, replace_value):\n",
    "        self.replace_value = replace_value\n",
    "        # replace_value = 'nan' for filling missing data in categorical features\n",
    "        # or -999 in numerical features\n",
    "       \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.replace_value)\n",
    "    \n",
    "    \n",
    "class ColumnApplier(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Some sklearn transformers can apply only on ONE column at a time (such as LabelEnconder())\n",
    "    Wrap them with ColumnApplier to apply on all columns in the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, underlying):\n",
    "        self.underlying = underlying\n",
    "        #TODO: underlying is one model method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        m = {}\n",
    "        X = pd.DataFrame(X)  # TODO: :( reimplement in pure numpy?\n",
    "        for c in X.columns:\n",
    "            k = clone(self.underlying) \n",
    "            #TODO: clone helps to construct a new estimator with the same parameters.\n",
    "            #      deep copy of the model in an estimator without actually copying attached data\n",
    "            \n",
    "            k.fit(X[c])\n",
    "            # fit model k for every column in X \n",
    "            \n",
    "            m[c] = k\n",
    "            # put it in dictionary with column c as key and k as items\n",
    "        \n",
    "        self._column_stages = m\n",
    "        # self.column_stages is a dictionary with column c in X as key and model k.fit as items \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        ret = {}\n",
    "        X = pd.DataFrame(X)\n",
    "        for c, k in self._column_stages.items():\n",
    "            ret[c] = k.transform(X[c])\n",
    "            # ret is a dict which has c as key and k.transform as items\n",
    "        return pd.DataFrame(ret)[X.columns]  # keep the same order\n",
    "\n",
    "class TolerantLabelEncoder(LabelEncoder):\n",
    "    \"\"\"\n",
    "    LabelEncoder is not tolerant to unseen values\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, y):\n",
    "        return np.searchsorted(self.classes_, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc = make_pipeline (\n",
    "    DropColumnsWithMissingData(thresholds=0.40),\n",
    "    make_union(\n",
    "    make_pipeline(\n",
    "        select_features(categorical_features),\n",
    "        FillMissingValues('nan'),\n",
    "        ColumnApplier(TolerantLabelEncoder())\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        select_features(numerical_features),\n",
    "        FillMissingValues(-999),\n",
    "        StandardScaler()\n",
    "        \n",
    "    )\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_n = y_train['target'].values\n",
    "skf = list(StratifiedKFold(y_train_n, n_folds= 5, shuffle=True, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['steps', 'pipeline', 'logisticregression', 'pipeline__steps', 'pipeline__dropcolumnswithmissingdata', 'pipeline__featureunion', 'pipeline__dropcolumnswithmissingdata__thresholds', 'pipeline__featureunion__n_jobs', 'pipeline__featureunion__transformer_list', 'pipeline__featureunion__transformer_weights', 'pipeline__featureunion__pipeline-1', 'pipeline__featureunion__pipeline-2', 'pipeline__featureunion__pipeline-1__steps', 'pipeline__featureunion__pipeline-1__select_features', 'pipeline__featureunion__pipeline-1__fillmissingvalues', 'pipeline__featureunion__pipeline-1__columnapplier', 'pipeline__featureunion__pipeline-1__select_features__features', 'pipeline__featureunion__pipeline-1__fillmissingvalues__replace_value', 'pipeline__featureunion__pipeline-1__columnapplier__underlying', 'pipeline__featureunion__pipeline-2__steps', 'pipeline__featureunion__pipeline-2__select_features', 'pipeline__featureunion__pipeline-2__fillmissingvalues', 'pipeline__featureunion__pipeline-2__standardscaler', 'pipeline__featureunion__pipeline-2__select_features__features', 'pipeline__featureunion__pipeline-2__fillmissingvalues__replace_value', 'pipeline__featureunion__pipeline-2__standardscaler__copy', 'pipeline__featureunion__pipeline-2__standardscaler__with_mean', 'pipeline__featureunion__pipeline-2__standardscaler__with_std', 'logisticregression__C', 'logisticregression__class_weight', 'logisticregression__dual', 'logisticregression__fit_intercept', 'logisticregression__intercept_scaling', 'logisticregression__max_iter', 'logisticregression__multi_class', 'logisticregression__n_jobs', 'logisticregression__penalty', 'logisticregression__random_state', 'logisticregression__solver', 'logisticregression__tol', 'logisticregression__verbose', 'logisticregression__warm_start'])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "        preproc, LogisticRegression())\n",
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_lg = {\n",
    "    'logisticregression__penalty': ('l1', 'l2'),\n",
    "    'logisticregression__C': [0.01, 0.1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_grid = GridSearchCV(pipeline, params_lg, cv = skf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_grid.fit(X_train, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score = model_grid.best_score_\n",
    "best_parameters = model_grid.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645331400579826"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters['logisticregression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_lg = best_parameters['logisticregression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg = make_pipeline(\n",
    "    preproc, clf_lg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mod_lg = lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49578993619090211"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lg = mod_lg.predict_proba(X_test)\n",
    "score = log_loss(y_test, y_pred_lg[:,1:])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['steps', 'pipeline', 'xgbclassifier', 'pipeline__steps', 'pipeline__dropcolumnswithmissingdata', 'pipeline__featureunion', 'pipeline__dropcolumnswithmissingdata__thresholds', 'pipeline__featureunion__n_jobs', 'pipeline__featureunion__transformer_list', 'pipeline__featureunion__transformer_weights', 'pipeline__featureunion__pipeline-1', 'pipeline__featureunion__pipeline-2', 'pipeline__featureunion__pipeline-1__steps', 'pipeline__featureunion__pipeline-1__select_features', 'pipeline__featureunion__pipeline-1__fillmissingvalues', 'pipeline__featureunion__pipeline-1__columnapplier', 'pipeline__featureunion__pipeline-1__select_features__features', 'pipeline__featureunion__pipeline-1__fillmissingvalues__replace_value', 'pipeline__featureunion__pipeline-1__columnapplier__underlying', 'pipeline__featureunion__pipeline-2__steps', 'pipeline__featureunion__pipeline-2__select_features', 'pipeline__featureunion__pipeline-2__fillmissingvalues', 'pipeline__featureunion__pipeline-2__standardscaler', 'pipeline__featureunion__pipeline-2__select_features__features', 'pipeline__featureunion__pipeline-2__fillmissingvalues__replace_value', 'pipeline__featureunion__pipeline-2__standardscaler__copy', 'pipeline__featureunion__pipeline-2__standardscaler__with_mean', 'pipeline__featureunion__pipeline-2__standardscaler__with_std', 'xgbclassifier__base_score', 'xgbclassifier__booster', 'xgbclassifier__colsample_bylevel', 'xgbclassifier__colsample_bytree', 'xgbclassifier__gamma', 'xgbclassifier__learning_rate', 'xgbclassifier__max_delta_step', 'xgbclassifier__max_depth', 'xgbclassifier__min_child_weight', 'xgbclassifier__missing', 'xgbclassifier__n_estimators', 'xgbclassifier__n_jobs', 'xgbclassifier__nthread', 'xgbclassifier__objective', 'xgbclassifier__random_state', 'xgbclassifier__reg_alpha', 'xgbclassifier__reg_lambda', 'xgbclassifier__scale_pos_weight', 'xgbclassifier__seed', 'xgbclassifier__silent', 'xgbclassifier__subsample'])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb = make_pipeline(\n",
    "        preproc, XGBClassifier()\n",
    ")\n",
    "pipeline_xgb.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    'xgbclassifier__n_estimators' : [30, 100, 300, 800],\n",
    "    'xgbclassifier__max_depth' : [3, 5, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_search = GridSearchCV(pipeline_xgb, params_xgb, cv = skf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([    0,     1, ..., 80022, 80023]), array([    2,    21, ..., 80014, 80015])), (array([    1,     2, ..., 80021, 80022]), array([    0,     4, ..., 80016, 80023])), (array([    0,     1, ..., 80022, 80023]), array([    3,    10, ..., 80013, 80019])), (array([    0,     1, ..., 80022, 80023]), array([    9,    15, ..., 80012, 80018])), (array([    0,     2, ..., 80019, 80023]), array([    1,     5, ..., 80021, 80022]))],\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('pipeline', Pipeline(steps=[('dropcolumnswithmissingdata', DropColumnsWithMissingData(thresholds=0.4)), ('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('select_features', select_features(features=Index(['v3', 'v22', 'v24', 'v31', 'v47', 'v52',...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'xgbclassifier__n_estimators': [30, 100, 300, 800], 'xgbclassifier__max_depth': [3, 5, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_search.fit(X_train, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestparams_xgb = xgb_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestparams_xgb['xgbclassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645331400579826"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_xgb = model_grid.best_score_\n",
    "best_score_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = make_pipeline(\n",
    "    preproc, bestparams_xgb['xgbclassifier']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/tu/miniconda3/envs/env36/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mod_xgb = xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46865203486185841"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xgb = mod_xgb.predict_proba(X_test)\n",
    "score_xgb = log_loss(y_test, y_pred_xgb[:,1:])\n",
    "score_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SearchBestParams(X_train, y_train, clf, params, cv = skf):\n",
    "    pipeline = make_pipeline(\n",
    "        preproc, clf)\n",
    "    search = GridSearchCV(pipeline, params, cv)\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    GetParams = search.best_estimator_.get_params()\n",
    "    return GetParams[clf.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lg = make_pipeline(\n",
    "        preproc, \n",
    "        GridSearchCV(\n",
    "            LogisticRegression(),\n",
    "                {\n",
    "                    'C' : [0.05, 0.1 , 1, 10], \n",
    "                    'penalty' : ('l2', 'l1') \n",
    "                    \n",
    "                },\n",
    "            cv = skf,\n",
    "            verbose=1, \n",
    "            scoring='log_loss'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 52.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pipeline', Pipeline(steps=[('dropcolumnswithmissingdata', DropColumnsWithMissingData(thresholds=0.4)), ('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('select_features', select_features(features=Index(['v3', 'v22', 'v24', 'v31', 'v47', 'v52',...re_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='log_loss', verbose=1))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lg.fit(X_train, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipeline_lg, open('pipeline_lg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_xgb = make_pipeline(\n",
    "        preproc, \n",
    "        GridSearchCV(\n",
    "            XGBClassifier(),\n",
    "                {\n",
    "                    'n_estimators' : [30, 100, 300, 800],\n",
    "                    'max_depth' : [3, 5, 7]\n",
    "                },\n",
    "            cv = skf,\n",
    "            verbose=1\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 96.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pipeline', Pipeline(steps=[('dropcolumnswithmissingdata', DropColumnsWithMissingData(thresholds=0.4)), ('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('select_features', select_features(features=Index(['v3', 'v22', 'v24', 'v31', 'v47', 'v52',...max_depth': [3, 5, 7]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=1))])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb.fit(X_train, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 300}"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pipeline_xgb.steps[-1][1]\n",
    "a.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.77842, std: 0.00178, params: {'max_depth': 3, 'n_estimators': 30},\n",
       " mean: 0.78032, std: 0.00214, params: {'max_depth': 3, 'n_estimators': 100},\n",
       " mean: 0.78074, std: 0.00184, params: {'max_depth': 3, 'n_estimators': 300},\n",
       " mean: 0.78057, std: 0.00119, params: {'max_depth': 3, 'n_estimators': 800},\n",
       " mean: 0.77993, std: 0.00203, params: {'max_depth': 5, 'n_estimators': 30},\n",
       " mean: 0.78059, std: 0.00236, params: {'max_depth': 5, 'n_estimators': 100},\n",
       " mean: 0.78018, std: 0.00183, params: {'max_depth': 5, 'n_estimators': 300},\n",
       " mean: 0.77877, std: 0.00205, params: {'max_depth': 5, 'n_estimators': 800},\n",
       " mean: 0.77989, std: 0.00202, params: {'max_depth': 7, 'n_estimators': 30},\n",
       " mean: 0.78063, std: 0.00221, params: {'max_depth': 7, 'n_estimators': 100},\n",
       " mean: 0.77972, std: 0.00251, params: {'max_depth': 7, 'n_estimators': 300},\n",
       " mean: 0.77592, std: 0.00225, params: {'max_depth': 7, 'n_estimators': 800}]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_xgb = pipeline_xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46926432423787995"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_xgb_1 = log_loss(y_test, y_pred_xgb[:,1:])\n",
    "score_xgb_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_et = make_pipeline(\n",
    "        preproc, \n",
    "        GridSearchCV(\n",
    "            ExtraTreesClassifier(),\n",
    "                {\n",
    "                    'n_estimators' : [30, 100, 300, 800],\n",
    "                    'max_depth' : [3, 5, 7]\n",
    "                },\n",
    "            cv = skf,\n",
    "            verbose=1, \n",
    "            scoring='accuracy'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_xgb.fit(X_train, y_train_n)\n",
    "BestEt = pipeline_xgb.best_estimator_.get_params()['extratreesclassifier']\n",
    "print(pipeline_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_rf = make_pipeline(\n",
    "        preproc, \n",
    "        GridSearchCV(\n",
    "            RandomForestClassifier(),\n",
    "                {\n",
    "                    'n_estimators' : [30, 100, 300, 800],\n",
    "                    'criterion' : ('gini', 'entropy'),\n",
    "                    'max_depth' : [3, 5, 7]\n",
    "                },\n",
    "            cv = skf,\n",
    "            verbose=1, \n",
    "            scoring='accuracy'\n",
    "        )\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_rf.fit(X_train, y_train_n)\n",
    "BestEt = pipeline_xgb.best_estimator_.get_params()['extratreesclassifier']\n",
    "print(pipeline_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TreatmentSpecialColumns(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column = 'v22', threshold = 50 ):\n",
    "        self.column = column\n",
    "        self.threshold = threshold \n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        values, counts = np.unique(X[self.column], return_counts=True)\n",
    "        counts = {x : y for x, y in zip(values, counts)}\n",
    "        X[self.column] = X[self.column].apply(lambda x: x if counts.get(x, 0) > self.threshold else 0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc = make_pipeline (\n",
    "    DropColumnsWithMissingData(thresholds=0.40),\n",
    "    make_union(\n",
    "    make_pipeline(\n",
    "        select_features(categorical_features),\n",
    "        FillMissingValues('nan'),\n",
    "        ColumnApplier(TolerantLabelEncoder()),\n",
    "        OneHotEncoder(handle_unknown = 'ignore')\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        select_features(numerical_features),\n",
    "        FillMissingValues(-999),\n",
    "        StandardScaler()        \n",
    "    )\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_ohe = make_pipeline(\n",
    "        preproc,\n",
    "        GridSearchCV(\n",
    "            XGBClassifier(),\n",
    "                {\n",
    "                    'n_estimators' : [30, 100, 300, 800],\n",
    "                    # Number of boosted trees to fit.\n",
    "                    'max_depth' : [ 3, 5, 7],\n",
    "                    'learning_rate': [0.1, 0.5]\n",
    "                }\n",
    "            \n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pipeline', Pipeline(steps=[('dropcolumnswithmissingdata', DropColumnsWithMissingData(thresholds=0.4)), ('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('select_features', select_features(features=Index(['v3', 'v22', 'v24', 'v31', 'v47', 'v52',...     pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_ohe.fit(X_train, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_ohe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46675254991029314"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_xgb = log_loss(y_test, y_pred_xgb[:,1:])\n",
    "score_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(xgb_ohe, open('xgb_ohe.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
